{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1db7bb5e-7f1d-46f8-9e64-c565bee4986f",
   "metadata": {},
   "source": [
    "# 1. 自回归模型（Autoregressive Model）\n",
    "\n",
    "自回归（AR）模型是一种时间序列模型，用于描述当前时刻的数据如何依赖于过去时刻的数据。它假设当前状态可以通过一个线性组合的方式由历史观测值来表示。\n",
    "\n",
    "## 数学表达式：\n",
    "自回归模型的一般形式为：\n",
    "$$\n",
    "y_t = \\alpha + \\sum_{i=1}^{p} \\beta_i y_{t-i} + \\epsilon_t\n",
    "$$\n",
    "其中：\n",
    "- $y_t$：表示时刻$t$的观测值。\n",
    "- $\\alpha$：常数项，表示模型的偏移量。\n",
    "- $\\beta_i$：表示过去第$i$个时刻对当前值的影响系数（AR系数）。\n",
    "- $p$：模型的阶数，表示回归时使用的过去时刻的数量。\n",
    "- $\\epsilon_t$：误差项，通常假设为白噪声，表示观测误差或系统无法捕捉的随机波动。\n",
    "\n",
    "## 关键特点：\n",
    "- **无记忆性**：当前时刻的值仅依赖于其前$p$个时刻的观测值，而与更早的观测值无关。\n",
    "- **线性关系**：假设数据之间是线性关系，因此适用于数据变化呈线性趋势的情况。\n",
    "\n",
    "## 应用场景：\n",
    "- 股票价格预测。\n",
    "- 气象数据分析。\n",
    "- 经济数据建模。\n",
    "\n",
    "# 2. 马尔可夫模型（Markov Model）\n",
    "\n",
    "马尔可夫模型是一类随机过程模型，描述一个系统从一个状态转移到另一个状态的过程。马尔可夫模型的核心特性是**马尔可夫性**，即系统的未来状态只与当前状态有关，与过去的历史状态无关。\n",
    "\n",
    "## 数学表达式：\n",
    "马尔可夫链的转移概率通常表示为：\n",
    "$$\n",
    "P(s_t | s_{t-1}, s_{t-2}, \\dots, s_0) = P(s_t | s_{t-1})\n",
    "$$\n",
    "其中：\n",
    "- $P(s_t | s_{t-1})$：表示在时刻$t-1$处于状态$s_{t-1}$时，转移到时刻$t$的状态$s_t$的概率。\n",
    "- 系统的状态空间为$\\{s_1, s_2, \\dots, s_n\\}$，每个状态的转移概率可以构成一个**转移矩阵**$P$。\n",
    "\n",
    "## 关键特点：\n",
    "- **无记忆性**：未来的状态只与当前状态有关，而与历史状态无关。\n",
    "- **状态转移**：系统的变化是通过状态之间的转移来描述的，每个状态到另一个状态的转移有一定的概率。\n",
    "\n",
    "## 应用场景：\n",
    "- 语音识别（隐马尔可夫模型）。\n",
    "- 机器人导航（路径规划）。\n",
    "- 文本生成、自然语言处理。\n",
    "\n",
    "# 3. 因果关系（Causal Relationship）\n",
    "\n",
    "因果关系是指一个事件（原因）会直接影响另一个事件（结果）。在数据分析和建模中，因果关系的建模非常重要，特别是在深度学习中，尤其是处理时间序列数据时。\n",
    "\n",
    "## 数学表达式：\n",
    "因果关系在数学上可以通过结构方程模型（SEM）、格兰杰因果检验（Granger Causality）等方法来描述。对于格兰杰因果检验，假设有两个时间序列$x_t$和$y_t$，我们可以表示因果关系为：\n",
    "$$\n",
    "y_t = \\sum_{i=1}^{p} \\beta_i x_{t-i} + \\epsilon_t\n",
    "$$\n",
    "或者\n",
    "$$\n",
    "x_t = \\sum_{i=1}^{p} \\gamma_i y_{t-i} + \\eta_t\n",
    "$$\n",
    "其中：\n",
    "- $\\beta_i$和$\\gamma_i$是回归系数，表示变量间的影响程度。\n",
    "- $\\epsilon_t$和$\\eta_t$是误差项，表示无法捕捉的噪声。\n",
    "\n",
    "## 关键特点：\n",
    "- **因果性**：因果关系不仅仅描述相关性，还说明了一个变量如何影响另一个变量。\n",
    "- **时间顺序性**：因果关系通常遵循时间顺序，前一个事件是后一个事件的原因。\n",
    "\n",
    "## 应用场景：\n",
    "- 经济学中的政策影响分析。\n",
    "- 物理学中事件的因果推理。\n",
    "- 神经科学中脑部活动与行为之间的因果关系分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d12ad-67e7-424f-844a-a2ece7254e5c",
   "metadata": {},
   "source": [
    "# 实操\n",
    "## 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91952938-e800-4313-8579-1247d3ff540c",
   "metadata": {},
   "source": [
    "首先生成一些数据：使用正弦函数和一些可加性噪声来生成序列数据，时间步为1, 2, . . . , 1000。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dc32683-6b50-49b3-98dc-53a4572e7560",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "197c3a67-f06e-427a-b83a-d637087d1c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1000 # 总共产生1000个点\n",
    "time = torch.arange(1, T + 1, dtype=torch.float32)\n",
    "x = torch.sin(0.01 * time) + torch.normal(0, 0.2, (T,))\n",
    "d2l.plot(time, [x], 'time', 'x', xlim=[1, 1000], figsize=(6, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5828f401-f0e8-4d19-88f3-5d4c246adb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义时间窗口大小 tau，表示用过去 tau 个时间步的数据来预测下一个时间步\n",
    "tau = 4\n",
    "\n",
    "# 初始化特征矩阵 features，形状为 (T - tau, tau)\n",
    "# T - tau 表示可以生成的样本数量，tau 表示每个样本的特征数量（时间窗口大小）\n",
    "features = torch.zeros((T - tau, tau))\n",
    "\n",
    "# 通过循环填充特征矩阵\n",
    "for i in range(tau):\n",
    "    # 将时间序列 x 的滑动窗口数据填充到 features 中\n",
    "    # x[i: T - tau + i] 表示从第 i 个时间步开始，取长度为 T - tau 的子序列\n",
    "    features[:, i] = x[i: T - tau + i]\n",
    "\n",
    "# 构建标签 labels，表示每个样本对应的目标值（下一个时间步的值）\n",
    "# x[tau:] 表示从第 tau 个时间步开始的所有值，reshape((-1, 1)) 将其转换为列向量\n",
    "labels = x[tau:].reshape((-1, 1))\n",
    "\n",
    "# 定义批量大小 batch_size 和训练样本数量 n_train\n",
    "batch_size, n_train = 16, 600\n",
    "\n",
    "# 创建训练数据加载器 train_iter\n",
    "# 使用前 n_train 个样本作为训练数据，features[:n_train] 是特征，labels[:n_train] 是标签\n",
    "# batch_size 表示每次迭代返回的批量大小，is_train=True 表示这是训练数据\n",
    "train_iter = d2l.load_array((features[:n_train], labels[:n_train]), batch_size, is_train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efc77d8-5ff0-4699-a4c3-5923a5f3bfbe",
   "metadata": {},
   "source": [
    "在这里，我们使用一个相当简单的架构训练模型：一个拥有两个全连接层的多层感知机，ReLU激活函数和平方损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "986d2d3a-68ce-4eec-89fd-217b30eca671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化网络权重的函数\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        \n",
    "# 一个简单的多层感知机\n",
    "def get_net():\n",
    "    net = nn.Sequential(nn.Linear(4, 10),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(10, 1))\n",
    "    net.apply(init_weights)\n",
    "    return net\n",
    "    \n",
    "# 平方损失。注意：MSELoss计算平方误差时不带系数1/2\n",
    "loss = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677d658c-fe84-4cb5-b511-f4523e3cd176",
   "metadata": {},
   "source": [
    "现在开始准备实现模型的训练，实现训练的基本代码与之前的基本类似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd946d75-2de9-4f39-9189-f5fb9fe90de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 0.049176\n",
      "epoch 2, loss: 0.048730\n",
      "epoch 3, loss: 0.045961\n",
      "epoch 4, loss: 0.045456\n",
      "epoch 5, loss: 0.044152\n"
     ]
    }
   ],
   "source": [
    "def train(net, train_iter, loss, epochs, lr):\n",
    "    trainer = torch.optim.Adam(net.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            l = loss(net(X), y)\n",
    "            l.sum().backward()\n",
    "            trainer.step()\n",
    "        print(f'epoch {epoch + 1}, '\n",
    "            f'loss: {d2l.evaluate_loss(net, train_iter, loss):f}')\n",
    "\n",
    "net = get_net()\n",
    "train(net, train_iter, loss, 5, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc5291f-75f1-406c-aec4-9d19917b4863",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7a1a45-1aec-4f60-9197-377c7a07a105",
   "metadata": {},
   "source": [
    "训练的损失是很小的，所以期望其有着较好的工作效果。现在来进行检验，首先是首先是检\n",
    "查模型预测下一个时间步的能力，也就是单步预测（one‐step‐ahead prediction）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59ea95cf-1b81-432c-bea7-467602728e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "onestep_preds = net(features)\n",
    "\n",
    "d2l.plot([time, time[tau:]],\n",
    "         [x.detach().numpy(), onestep_preds.detach().numpy()], 'time',\n",
    "         'x', legend=['data', '1-step preds'], xlim=[1, 1000],\n",
    "         figsize=(6, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c461021-5ca2-41e0-a948-e663a33b9691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
