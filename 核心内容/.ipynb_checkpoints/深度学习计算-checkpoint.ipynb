{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e6c2bbe-d05e-43b5-9d9c-3a4599d4231d",
   "metadata": {},
   "source": [
    "# 关于层和块"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c193eb-c0a0-41f4-a963-83caa2a902eb",
   "metadata": {},
   "source": [
    "## 自定义块"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fa6ac9-a0cc-4289-a32a-f962fe23b951",
   "metadata": {},
   "source": [
    "在下面的代码片段中，我们从零开始编写一个块。它包含一个多层感知机，其具有256个隐藏单元的隐藏层和一\n",
    "个10维输出层。注意，下面的MLP类继承了表示块的类。我们的实现只需要提供我们自己的构造函数（Python中\n",
    "的__init__函数）和前向传播函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a0d2a8-b9ff-4b59-a85b-62ece70727d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# 定义一个多层感知机（MLP）类，继承自 nn.Module\n",
    "class MLP(nn.Module):\n",
    "    # 初始化方法，用于定义模型的层\n",
    "    def __init__(self):\n",
    "        # 调用父类 nn.Module 的初始化方法\n",
    "        super().__init__()\n",
    "        \n",
    "        # 定义隐藏层：输入特征数为 20，输出特征数为 256\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        \n",
    "        # 定义输出层：输入特征数为 256，输出特征数为 10\n",
    "        self.out = nn.Linear(256, 10)\n",
    "\n",
    "    # 定义前向传播方法，描述如何根据输入计算输出\n",
    "    def forward(self, X):\n",
    "        # 将输入 X 传递给隐藏层，并应用 ReLU 激活函数\n",
    "        hidden_output = F.relu(self.hidden(X))\n",
    "        \n",
    "        # 将隐藏层的输出传递给输出层，得到最终的输出\n",
    "        output = self.out(hidden_output)\n",
    "        \n",
    "        # 返回输出结果\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffca3e54-5dc2-4963-b043-c9c7d595fa37",
   "metadata": {},
   "source": [
    "接下来进行一个实例化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c25f591-ade2-4b4d-be57-7efc92b7e392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0196, -0.1717, -0.0400, -0.0408, -0.1197,  0.1120, -0.0521, -0.1820,\n",
       "          0.0439,  0.0218],\n",
       "        [ 0.0612, -0.1745, -0.0023, -0.1297, -0.1790,  0.0759, -0.2485, -0.2383,\n",
       "          0.1429,  0.0845]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MLP()\n",
    "X = torch.rand(2, 20)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b35b8b4-ad7e-43a4-a732-85438b5f045a",
   "metadata": {},
   "source": [
    "## 顺序块"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6fbab9-410b-4ea8-9ac3-6989b09cd291",
   "metadata": {},
   "source": [
    "主要是Sequential类的工作模式，尝试构建的简化的MySequential，我们只需要定义两个关键函数：\n",
    "1. 一种将块逐个追加到列表中的函数；\n",
    "2. 一种前向传播函数，用于将输入按追加块的顺序传递给块组成的“链条”。\n",
    "\n",
    "以下是相关代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da34f5a-cfd8-4f5f-a5ba-d79298f2cf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义顺序容器类 MySequential\n",
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        # 遍历传入的模块，并将它们添加到 _modules 中\n",
    "        for idx, module in enumerate(args):\n",
    "            # _modules 是 nn.Module 的成员变量，类型为 OrderedDict\n",
    "            self._modules[str(idx)] = module\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 按顺序遍历 _modules 中的模块，并依次调用\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444d4197-f72c-45ae-ba6b-271e17c9e85e",
   "metadata": {},
   "source": [
    "实现实例并进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f57ef0d-bc70-4f7f-a72b-25e43da0ce96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0284, -0.0355,  0.1432,  0.3371, -0.0323,  0.0877, -0.0484,  0.0901,\n",
       "         -0.1203, -0.1952],\n",
       "        [ 0.0090,  0.0335,  0.1910,  0.4235, -0.0527,  0.0009, -0.0274,  0.1611,\n",
       "         -0.1620, -0.1964]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad95587-6f6a-4f07-b8b5-98799677763d",
   "metadata": {},
   "source": [
    "## 在前向传播函数中执行代码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d0760a-a1a3-488b-803a-cc15af3bccb4",
   "metadata": {},
   "source": [
    "`Sequential` 类极大地简化了模型的构建过程，允许我们通过组合现有模块来创建新的架构，而无需手动定义新的类。然而，并非所有架构都遵循简单的顺序结构。当需要更高的灵活性时，我们必须自定义模型块。例如，我们可能希望在前向传播过程中引入 Python 的控制流（如条件判断或循环），或者执行一些自定义的数学运算，而不仅仅是依赖预定义的神经网络层。\n",
    "\n",
    "到目前为止，我们讨论的网络中的所有操作都作用于网络的激活值或可训练参数。然而，在某些情况下，我们可能需要引入一些既不是前一层输出也不是可训练参数的项，这些项被称为**常数参数**（constant parameter）。例如，假设我们需要实现一个计算函数 $ f(x, w) = c \\cdot w^\\top x $ 的层，其中 $ x $ 是输入，$ w $ 是可训练参数，而 $ c $ 是一个在优化过程中不会更新的固定常量。为了实现这样的功能，我们可以定义一个自定义类 `FixedHiddenMLP`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24f0a330-8bc5-4b3c-ae3f-79c90f2ae652",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 不计算梯度的随机权重参数。因此其在训练期间保持不变\n",
    "        self.rand_weight = torch.rand((20, 20), requires_grad=False)\n",
    "        self.linear = nn.Linear(20, 20)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.linear(X)\n",
    "        # 使用创建的常量参数以及relu和mm函数\n",
    "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
    "        # 复用全连接层。这相当于两个全连接层共享参数\n",
    "        X = self.linear(X)\n",
    "        # 控制流\n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "        return X.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091687be-cef2-4066-8159-dfc25bd49fab",
   "metadata": {},
   "source": [
    "在这个FixedHiddenMLP模型中，我们实现了一个隐藏层，其权重（self.rand_weight）在实例化时被随机初\n",
    "始化，之后为常量。这个权重不是一个模型参数，因此它永远不会被反向传播更新。然后，神经网络将这个\n",
    "固定层的输出通过一个全连接层。\n",
    "\n",
    "在返回输出之前，模型做了一些不寻常的事情：它运行了一个while循环，在L1范数大于1的条件下，将\n",
    "输出向量除以2，直到它满足条件为止。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41fe7480-7797-4b17-a032-d1ab312e922f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0399, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FixedHiddenMLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5ebf26-7be6-4f3c-aa80-3a8792697671",
   "metadata": {},
   "source": [
    "我们可以混合搭配各种组合块的方法。在下面的例子中，我们以一些想到的方法嵌套块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dacb050-e1fa-47e5-8cbd-a0e1c4401338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1549, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(),\n",
    "                                 nn.Linear(64, 32), nn.ReLU())\n",
    "        self.linear = nn.Linear(32, 16)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.linear(self.net(X))\n",
    "        \n",
    "chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixedHiddenMLP())\n",
    "chimera(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8e1298-4db4-4086-af9b-82d8ddcf6f1b",
   "metadata": {},
   "source": [
    "# 关于参数管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b05beb4e-84d4-43fb-b710-6fbb513eec34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1701],\n",
       "        [0.0988]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n",
    "X = torch.rand(size=(2, 4))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0772f5-5c06-48d6-8062-b5918fc73a75",
   "metadata": {},
   "source": [
    "## 参数访问\n",
    "我们从已有模型中访问参数。当通过Sequential类定义模型时，我们可以通过索引来访问模型的任意层。这\n",
    "就像模型是一个列表一样，每层的参数都在其属性中。如下所示，我们可以检查第二个全连接层的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee2c96b5-4556-40e4-8965-f9d832b984ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight', tensor([[ 0.1586,  0.1788, -0.3422, -0.2022, -0.0853,  0.0258, -0.1181,  0.2561]])), ('bias', tensor([0.1633]))])\n"
     ]
    }
   ],
   "source": [
    "print(net[2].state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09ba6c4-3153-4f6d-af91-6b5611247e81",
   "metadata": {},
   "source": [
    "### 目标参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f80cdfb-6220-4189-9ba7-55e0dec686d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n",
      "Parameter containing:\n",
      "tensor([0.1633], requires_grad=True)\n",
      "tensor([0.1633])\n"
     ]
    }
   ],
   "source": [
    "print(type(net[2].bias))\n",
    "print(net[2].bias)\n",
    "print(net[2].bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b08a5b0-e5e5-41da-959d-6035f0699f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].weight.grad == None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f5ed93-7bf1-46f1-a55b-95dce3a0c628",
   "metadata": {},
   "source": [
    "### 一次性访问所有参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378ade4e-2c1f-4f16-bf12-5791acf2217c",
   "metadata": {},
   "source": [
    "当我们需要对所有参数执行操作时，逐个访问它们可能会很麻烦。当我们处理更复杂的块（例如，嵌套块）\n",
    "时，情况可能会变得特别复杂，因为我们需要递归整个树来提取每个子块的参数。下面，我们将通过演示来\n",
    "比较访问第一个全连接层的参数和访问所有层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79fb3738-2bfa-476b-9dc8-2a89323ad0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n",
      "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
     ]
    }
   ],
   "source": [
    "print(*[(name, param.shape) for name, param in net[0].named_parameters()])\n",
    "print(*[(name, param.shape) for name, param in net.named_parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95b879d-e1e0-4502-a381-461218739c4b",
   "metadata": {},
   "source": [
    "这为我们提供了另一种访问网络参数的方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3794969-e6f2-4fb0-a5f5-10ff036f1ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1633])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()['2.bias'].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26129cfe-6e48-4753-b67b-45c86e6470ee",
   "metadata": {},
   "source": [
    "### 从嵌套块收集参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b070a619-ae04-4396-8adc-dc17dad69830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2224],\n",
       "        [-0.2224]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def block1():\n",
    "    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
    "                         nn.Linear(8, 4), nn.ReLU())\n",
    "\n",
    "def block2():\n",
    "    net = nn.Sequential()\n",
    "    for i in range(4):\n",
    "        # 在这里嵌套\n",
    "        net.add_module(f'block {i}', block1())\n",
    "    return net\n",
    "\n",
    "rgnet = nn.Sequential(block2(), nn.Linear(4, 1))\n",
    "rgnet(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036afdc7-e78d-4785-820e-6677e704cc3f",
   "metadata": {},
   "source": [
    "设计了网络后，我们看看它是如何工作的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df9f41eb-29fe-430f-9aa1-d620c7ac3826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (block 0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 3): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(rgnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebe5b3e-e05d-4a96-bc53-4a02fc17c38f",
   "metadata": {},
   "source": [
    "因为层是分层嵌套的，所以我们也可以像通过嵌套列表索引一样访问它们。下面，我们访问第一个主要的块\n",
    "中、第二个子块的第一层的偏置项。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f35e7111-2aa4-4396-a343-7c6843046d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1353,  0.2643, -0.0047, -0.3632,  0.3044,  0.0696,  0.4317,  0.1364])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet[0][1][0].bias.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5844b06f-9db1-4e2b-8f02-36f85c4b0c4a",
   "metadata": {},
   "source": [
    "## 参数初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b36555-3e7a-4b68-a5ff-5bea9f536887",
   "metadata": {},
   "source": [
    "深度学习框架提供默认随机初始化，也允许我们创建自定义初始化方法，满足我们通过其他规则实现初始化权重。\n",
    "\n",
    "默认情况下，PyTorch会根据一个范围均匀地初始化权重和偏置矩阵，这个范围是根据输入和输出维度计算出的。PyTorch的nn.init模块提供了多种预置初始化方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ceb630-c27a-4d1f-a48a-86f30b4f3b8e",
   "metadata": {},
   "source": [
    "### 内置初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3250d73b-a67c-4071-80fa-4d224f0644df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0078,  0.0109,  0.0045,  0.0040]), tensor(0.))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义初始化函数\n",
    "def init_normal(m):\n",
    "    \"\"\"\n",
    "    初始化神经网络中的线性层（nn.Linear）的权重和偏置。\n",
    "    权重使用正态分布初始化，偏置使用零初始化。\n",
    "    \"\"\"\n",
    "    if type(m) == nn.Linear:  # 检查模块是否为线性层\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)  # 初始化权重：均值为 0，标准差为 0.01\n",
    "        nn.init.zeros_(m.bias)  # 初始化偏置：值为 0\n",
    "        \n",
    "net.apply(init_normal)\n",
    "net[0].weight.data[0], net[0].bias.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8bc4e4-62f7-45d9-91b3-0d5aa56140ed",
   "metadata": {},
   "source": [
    "我们还可以将所有参数初始化为给定的常数，比如初始化为1。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada409a8-6d3f-4937-b2fe-c7344c888597",
   "metadata": {},
   "source": [
    "def init_constant(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "net.apply(init_constant)\n",
    "net[0].weight.data[0], net[0].bias.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6e9c4f-0476-4921-85d0-23bd7f6bb7cb",
   "metadata": {},
   "source": [
    "我们还可以对某些块应用不同的初始化方法。例如，下面我们使用Xavier初始化方法初始化第一个神经网络\n",
    "层，然后将第三个神经网络层初始化为常量值42。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0c2ae13-0ed7-4e11-81cb-5ef9b2707cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6525, -0.0530, -0.5031,  0.4587])\n",
      "tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n"
     ]
    }
   ],
   "source": [
    "def init_xavier(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        \n",
    "def init_42(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 42)\n",
    "        \n",
    "net[0].apply(init_xavier)\n",
    "net[2].apply(init_42)\n",
    "\n",
    "print(net[0].weight.data[0])\n",
    "print(net[2].weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bd1239-d6f2-45f8-89ef-bf4ee1576e3f",
   "metadata": {},
   "source": [
    "### 自定义的初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd29f8a0-2586-4bdf-a6c4-ab99a4f7c07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init weight torch.Size([8, 4])\n",
      "Init weight torch.Size([1, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  9.3591,  6.9189, -0.0000],\n",
       "        [-0.0000, -7.0772,  5.8547,  0.0000]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        print(\"Init\", *[(name, param.shape)\n",
    "                        for name, param in m.named_parameters()][0])\n",
    "        nn.init.uniform_(m.weight, -10, 10)\n",
    "        m.weight.data *= m.weight.data.abs() >= 5\n",
    "\n",
    "net.apply(my_init)\n",
    "net[0].weight[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e7367c3-0d5c-404c-adfe-dcc1dbba1ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([42.0000, 10.3591,  7.9189,  1.0000])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data[:] += 1\n",
    "net[0].weight.data[0, 0] = 42\n",
    "net[0].weight.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9a448f-ab5d-4bcc-a1c3-3dcc46fa45ee",
   "metadata": {},
   "source": [
    "## 参数绑定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187fe4d7-9ce0-4d64-88f5-aa6074c469b2",
   "metadata": {},
   "source": [
    "有时我们希望在多个层间共享参数：我们可以定义一个稠密层，然后使用它的参数来设置另一个层的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59df0530-2af0-4c64-948a-badb726db352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "# 我们需要给共享层一个名称，以便可以引用它的参数\n",
    "shared = nn.Linear(8, 8)\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
    "                    shared, nn.ReLU(),\n",
    "                    shared, nn.ReLU(),\n",
    "                    nn.Linear(8, 1))\n",
    "\n",
    "net(X)\n",
    "# 检查参数是否相同\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
    "net[2].weight.data[0, 0] = 100\n",
    "# 确保它们实际上是同一个对象，而不只是有相同的值\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887dfe9a-0c08-47db-8af3-094e517f5df1",
   "metadata": {},
   "source": [
    "# 延后初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc1d47-7da3-4756-b648-a2347426e95b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 1. **核心思想**\n",
    "- **延迟初始化**：在模型定义时，不立即初始化参数（如权重和偏置），而是记录参数的结构。\n",
    "- **动态推断**：在第一次前向传播时，根据输入数据的形状（如批量大小和特征维度）推断参数的实际形状并初始化。\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **数学表示**\n",
    "对于一个线性层 $y = Wx + b$：\n",
    "- 输入 $x$ 的形状为 $(batch\\_size, in\\_features)$。\n",
    "- 权重 $W$ 的形状为 $(out\\_features, in\\_features)$。\n",
    "- 偏置 $b$ 的形状为 $(out\\_features,)$。\n",
    "\n",
    "在延后初始化中：\n",
    "- 模型定义时，$W$ 和 $b$ 的形状未知。\n",
    "- 第一次前向传播时，根据输入 $x$ 的形状动态推断 $W$ 和 $b$ 的形状并初始化。\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **优点**\n",
    "1. **灵活性**：支持动态输入形状，适用于不同任务和数据集。\n",
    "2. **节省内存**：在模型定义时不立即分配参数的内存，减少内存占用。\n",
    "3. **简化代码**：无需手动指定输入形状，代码更简洁。\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **缺点**\n",
    "1. **调试困难**：参数初始化被延迟，调试时难以确定参数的实际形状。\n",
    "2. **性能开销**：第一次前向传播时需要动态推断参数形状并初始化，可能增加计算开销。\n",
    "\n",
    "---\n",
    "\n",
    "## 5. **适用场景**\n",
    "- 输入数据的形状在模型定义时未知（如动态批量大小或特征维度）。\n",
    "- 需要灵活处理不同输入形状的任务。\n",
    "｜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5760f15b-f202-4f93-8b66-1ed4c4312c43",
   "metadata": {},
   "source": [
    "# 关于自定义层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9717237a-f22b-4808-836d-5337a3668852",
   "metadata": {},
   "source": [
    "深度学习成功背后的一个因素是神经网络的灵活性：我们可以用创造性的方式组合不同的层，从而设计出适\n",
    "用于各种任务的架构。例如，研究人员发明了专门用于处理图像、文本、序列数据和执行动态规划的层。有时\n",
    "我们会遇到或要自己发明一个现在在深度学习框架中还不存在的层。在这些情况下，必须构建自定义层。本\n",
    "节将展示如何构建自定义层。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167e044c-c5e3-45ab-ae35-e2dc4d115050",
   "metadata": {},
   "source": [
    "## 不带参数的层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee6af69-94f5-4edb-af6d-c3c2581b42d9",
   "metadata": {},
   "source": [
    "下面的CenteredLayer类要从其输入中减去均值。要构建它，我们只需继承基础层类并实现前向传播功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fed46c66-41d3-466f-aa53-7dcc01ac475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return X - X.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77589aee-ab06-47ed-89e1-ad332dafc05e",
   "metadata": {},
   "source": [
    "们向该层提供一些数据，验证它是否能按预期工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73f4c60d-a922-44a6-a1ba-a011db9d13d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = CenteredLayer()\n",
    "layer(torch.FloatTensor([1, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed87685-d898-4da1-a741-80208ae51a90",
   "metadata": {},
   "source": [
    "现在可以将层作为组件合并到更复杂的模型中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9459b0f1-b252-4047-8937-4a2e0d011cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542937e9-3370-4430-8b3e-763f4c14eb8e",
   "metadata": {},
   "source": [
    "作为额外的健全性检查，我们可以在向该网络发送随机数据后，检查均值是否为0。由于我们处理的是浮点\n",
    "数，因为存储精度的原因，我们仍然可能会看到一个非常小的非零数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31f8a486-dc01-4897-a352-77fca1c53859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.8626e-09, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = net(torch.rand(4, 8))\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fbbc5e-0f85-4e92-b738-78ee3ce20646",
   "metadata": {},
   "source": [
    "## 带参数的层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389d8bd5-adb2-4c65-b816-17b16fb12702",
   "metadata": {},
   "source": [
    "们继续定义具有参数的层，这些参数可以通过训练进行调整。我们可以使用内置函数来创建参数，这些函数提供一些基本的管理功能。比如管理访问、初始化、共享、保存和加载模型参数。这样做的好处之一是：我们不需要为每个自定义层编写自定义的序列化程序。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c3c04c-81d4-4845-9596-5d0d18b9b7cc",
   "metadata": {},
   "source": [
    "现在，让我们实现自定义版本的全连接层。回想一下，该层需要两个参数，一个用于表示权重，另一个用于表示偏置项。在此实现中，我们使用修正线性单元作为激活函数。该层需要输入参数：in_units和units，分别表示输入数和输出数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b746e2b0-603e-4faa-9529-2794c392c08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        \"\"\"\n",
    "        初始化函数，定义层的参数。\n",
    "        \n",
    "        参数:\n",
    "        - in_units: 输入特征的维度（输入神经元数量）。\n",
    "        - units: 输出特征的维度（输出神经元数量）。\n",
    "        \"\"\"\n",
    "        super().__init__()  # 调用父类 nn.Module 的初始化方法\n",
    "        \n",
    "        # 定义权重参数，形状为 (in_units, units)，并用正态分布随机初始化\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
    "        \n",
    "        # 定义偏置参数，形状为 (units,)，并用正态分布随机初始化\n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        前向传播函数，定义输入数据如何通过该层进行计算。\n",
    "        \n",
    "        参数:\n",
    "        - X: 输入数据，形状为 (batch_size, in_units)。\n",
    "        \n",
    "        返回:\n",
    "        - 输出数据，形状为 (batch_size, units)。\n",
    "        \"\"\"\n",
    "        # 计算线性变换：X * weight + bias\n",
    "        linear = torch.matmul(X, self.weight) + self.bias\n",
    "        \n",
    "        # 对线性变换的结果应用 ReLU 激活函数\n",
    "        return F.relu(linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb74744b-8823-4959-8cfa-00e036b5ded5",
   "metadata": {},
   "source": [
    "接下来，我们实例化MyLinear类并访问其模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "463debfd-abe9-4d9b-b24e-b015a8c18ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.4568,  0.1213,  0.1145],\n",
       "        [ 0.4236,  0.3502,  0.1224],\n",
       "        [-0.5629,  0.0027, -1.1536],\n",
       "        [ 0.9880, -0.1309, -0.3921],\n",
       "        [-0.1762, -0.3304,  0.3029]], requires_grad=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = MyLinear(5, 3)\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd18e4cd-eea9-47b4-8ff3-de7268b71bd8",
   "metadata": {},
   "source": [
    "我们可以使用自定义层直接执行前向传播计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "930882d7-bbf2-4ce2-91a4-90c02cbbb7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0845, 0.0263, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(torch.rand(2, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72068733-66be-4c5c-8092-024e636ca616",
   "metadata": {},
   "source": [
    "我们还可以使用自定义层构建模型，就像使用内置的全连接层一样使用自定义层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32964a19-9df8-4b15-a218-477227dab94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8360],\n",
       "        [0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
    "net(torch.rand(2, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceb9355-3033-421b-98d8-36e50e5cb560",
   "metadata": {},
   "source": [
    "# 关于读写文件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098a90e7-8009-48b2-833a-442953a18dbc",
   "metadata": {},
   "source": [
    "## 加载和保存张量\n",
    "对于单个张量，我们可以直接调用load和save函数分别读写它们。这两个函数都要求我们提供一个名称，save要\n",
    "求将要保存的变量作为输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7b46f6cc-87d3-4ba5-bc52-630f6354266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "x = torch.arange(4)\n",
    "torch.save(x, 'x-file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f38c6b-5052-4b99-b07a-40fe03a09ae2",
   "metadata": {},
   "source": [
    "此时我们可以将数据回读"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c655fa10-be50-454b-812a-087416021dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/c4qjdkd94t990kmb846tzgc40000gn/T/ipykernel_73705/1444019752.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x2 = torch.load('x-file')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.load('x-file')\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafc2a56-5486-4ef7-94b0-7a51a0fd98f2",
   "metadata": {},
   "source": [
    "我们可以存储一个张量列表，然后把它们读回内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "91e7ddba-cc1d-422e-bea3-c1c98397f3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/c4qjdkd94t990kmb846tzgc40000gn/T/ipykernel_73705/2924237495.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x2, y2 = torch.load('x-files')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros(4)\n",
    "torch.save([x, y],'x-files')\n",
    "x2, y2 = torch.load('x-files')\n",
    "(x2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a741d3cb-4add-447e-a1c7-18abce0d5f4a",
   "metadata": {},
   "source": [
    "我们也可以写入或读取从字符串映射到张量的字典。当我们要读取或写入模型中的所有权重时，这很方便。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "41faabea-d44a-47b3-aa01-898b23648f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/c4qjdkd94t990kmb846tzgc40000gn/T/ipykernel_73705/2269971588.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mydict2 = torch.load('mydict')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x': x, 'y': y}\n",
    "torch.save(mydict, 'mydict')\n",
    "mydict2 = torch.load('mydict')\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb6e684-d48e-4742-8b42-458ded96d54c",
   "metadata": {},
   "source": [
    "## 加载和保存模型参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3380334e-06d8-4c4f-aac0-c367eb3d6e00",
   "metadata": {},
   "source": [
    "保存单个权重向量（或其他张量）确实有用，但是如果我们想保存整个模型，并在以后加载它们，单独保存\n",
    "每个向量则会变得很麻烦。毕竟，我们可能有数百个参数散布在各处。因此，深度学习框架提供了内置函数\n",
    "来保存和加载整个网络。需要注意的一个重要细节是，这将保存模型的参数而不是保存整个模型。例如，如\n",
    "果我们有一个3层多层感知机，我们需要单独指定架构。因为模型本身可以包含任意代码，所以模型本身难以\n",
    "序列化。因此，为了恢复模型，我们需要用代码生成架构，然后从磁盘加载参数。让我们从熟悉的多层感知\n",
    "机开始尝试一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6425b61-cb8f-4496-a879-b0039a0089a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034c9bb7-d163-450a-b875-66aa7f979f31",
   "metadata": {},
   "source": [
    "接下来将模型的参数存储在一个叫做“mlp.params”的文件中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "48b8d2ad-b653-4b2e-b415-f06c7ca1c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'mlp.params')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a796023-85cd-4b51-8933-a4de51673359",
   "metadata": {},
   "source": [
    "为了恢复模型，我们实例化了原始多层感知机模型的一个备份。这里我们不需要随机初始化模型参数，而是\n",
    "直接读取文件中存储的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1a310b91-4cb1-4742-b877-ced883e5bb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/c4qjdkd94t990kmb846tzgc40000gn/T/ipykernel_73705/2014828273.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  clone.load_state_dict(torch.load('mlp.params'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('mlp.params'))\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25f7e99-c750-4b20-a7f6-80de8e3e9423",
   "metadata": {},
   "source": [
    "由于两个实例具有相同的模型参数，在输入相同的X时，两个实例的计算结果应该相同。让我们来验证一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fe9349fd-0468-4cc6-a8d1-7170c370f955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
